---
title: Redis是如何执行的
date: 2022-08-08 +/-TTTT
categories: [数据库, Redis]
tags: []     # TAG names should always be lowercase
---

# 一条Redis命令是如何执行的
我们从客户端输入一条命令到服务端执行这条命令究竟发生了什么，今天就来探讨这个问题

# 转换命令为Redis协议
客户端并不会把我们输入的命令直接发送给服务端，任何客户端服务端之间的通信都遵循某种协议，这种协议方便服务端对命令进行解析，例如判断命令拼写是否错误

Redis客户端会将命令转换为RESP格式，RESP（REdis Serialization Protocol）然后发送给客户端

1. 当然在这之前客户端会和服务端建立Socket连接，每个Socket被创建，会分配两个缓冲区：输入缓冲区和输出缓冲区，
2. 写入函数并不会立即向网络中传输数据，而是先将数据写入缓冲区中，再由 TCP 协议将数据从缓冲区发送到目标机器。一旦将数据写入到缓冲区，函数就可以成功返回，不管它们有没有到达目标机器，也不管它们何时被发送到网络，这些都是TCP协议负责的事情。 
3. 读取函数也是如此，它也是从输入缓冲区中读取数据，而不是直接从网络中读取。

**注意：Redis 使用的是 I/O 多路复用功能来监听多 socket 链接的，这样就可以使用一个线程链接来处理多个请求，减少线程切换带来的开销，同时也避免了 I/O 阻塞操作，从而大大提高了 Redis 的运行效率。**

# 用户空间和内核空间
以Linux系统为例，各种发行版包括：Ubuntu、CentOS，通常会包含它的应用程序和内核，一般内核是没有区别的，Linux内核就相当与Window操作系统，它通常与各种硬件驱动配合操作各种计算机硬件资源（CPU、内存、网卡），而用户应用如果要访问系统资源就必须使用Linux内核封装后提供的API（我们毕竟不能让用户应用直接访问系统资源，这样存在巨大的安全问题以及冲突），所以我们有必要将Linux内核和用户应用进行分离

以32位的计算机来说，内存总空间是2^32位，也就是4GB，通常内核空间会占用1GB，用户空间会占用3GB
![内核空间与用户空间](/blog/202208091618605.png "Optional title")

这样用户进程和内核进程在寻址时（进程的寻址空间其实就映射到了磁盘空间）就会完全隔离，同时Linux对各种命令进行分级，有两个级别：r0和r3，其中r3级别最低，用户进程能够执行的命令一般就是r3级别的，而r0是级别最高的，只有内核才能执行，这样对命令分配权限就限制了用户进程对系统资源的随意访问

但是用户进程有时又必须访问系统资源，这个时候就需要进行状态切换，也就是用户态 ---> 内核态

我们以磁盘操作为例，用户进程在写数据和读数据是都会操作缓存空间，写的时候先把数据写到缓存区，读的时候就从缓存区读，具体的状态切换的过程如下图：
![用户进程磁盘操作的状态切换](/blog/202208091627882.png "Optional title")

网络IO同磁盘操作，总结来说IO操作的时间消耗主要体现在：

1. 进程等待数据就绪
2. 数据从内核空间拷贝到用户空间

而后面将要提到的五种IO模型都是从这两方面去进行优化的

# 五种IO模型
## 阻塞IO
![阻塞IO的执行流程](/blog/202208091640324.png "Optional title")

1. 用户进程调用系统API-recvfrom
2. 内核会检查内核缓冲区数据是否准备就绪
3. 如果数据没有就绪，就会一直等待直到数据就绪
4. 数据就绪后还没完，进程还需等待数据从内核缓冲区拷贝到用户缓冲区
5. 当这个完成recvfrom返回OK的信息，整个调用就完成了

总结来看阻塞IO在数据等待和数据拷贝这两个阶段一直处于阻塞状态（除了等待操作完成，它什么都没干，cup处于闲置状态，所以阻塞IO效率很低）

## 非阻塞IO
![非阻塞IO的执行流程](/blog/202208091647693.png "Optional title")

对比阻塞IO，非阻塞IO就不等待
1. 如果数据没有就绪，直接返回错误结果
2. 然后一直盲轮询询问数据是否就绪，
3. 直到数据真正就绪，便等待数据拷贝
4. 拷贝完成后，整个操作就完成了

总结来说：非阻塞IO在数据等待阶段确实是非阻塞的，但这段时候它做的操作只是盲轮询，并没有做什么更有意义的操作，这样它性能不仅没有提高还会导致cpu空转，cpu使用率暴增，而且在数据拷贝阶段它依然是阻塞的

虽然非阻塞IO看起来非常废，但是在IO多路复用需要结合它发挥作用

## IO多路复用
![IO多路复用简介](/blog/202208091706149.png "Optional title")

总结阻塞IO和非阻塞IO，我们能够发现：
在调用系统API之后性能问题总是出现在数据等待阶段，这段时期阻塞IO会一直等待、非阻塞IO不等待但会一直轮询使得cpu空转利用率暴增，这些操作都导致了性能问题
所以为了避免这种问题，我们就提前询问内核那些系统数据准备好了，然后再去调用系统API

问题就是我们如何得知系统数据准备好了呢？

1. 文件描述符
![文件描述符简介](/blog/202208091736829.png "Optional title")

在调用recvfrom之前调用select监听fd是否就绪，如果所有fd都没有就绪就会阻塞等待否则就会返回就绪的fd，
此时调用recvfrom就会直接执行拷贝数据阶段

对比于阻塞IO和非阻塞IO，IO多路复用避免了可能存在已经就绪的fd被阻塞而进行无效的等待

2. 不同的监听fd以及通知的方式

- select
- poll
- epoll

select和epoll的操作大致一致，epoll的性能最好，通常高性能网络服务器一般操作epoll这种方式，如果epoll这种方式在操作系统上不支持就会采用select，因为select通用性更好，基本所有系统都支持

它们的具体差异体现在：

1. select和poll只会返回已就绪fd的数量，实际操作fd的时候需要遍历，而epoll会直接返回已经就绪的fd
2. epoll会在通知用户进程fd就绪的同时，就把就绪的fd写入了用户空间

总结来说：IO多路复用就是利用单个线程来同时监听多个fd，并在某个fd可读、可写时得到通知，从而避免无效的等待，充分利用cpu资源

### IO多路复用-select实现方案



## 信号驱动IO和异步IO